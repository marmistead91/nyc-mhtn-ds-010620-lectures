{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running an XGboosted Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the appropriate packages\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, f1_score, roc_auc_score\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data and split data to be used in the models\n",
    "titanic = pd.read_csv('cleaned_titanic.csv', index_col='PassengerId')\n",
    "\n",
    "# Create matrix of features\n",
    "X = titanic.drop('Survived', axis = 1) # grabs everything else but 'Survived'\n",
    "\n",
    "# Create target variable\n",
    "y = titanic['Survived'] # y is the column we're trying to predict\n",
    "\n",
    "# Create a list of the features being used in the \n",
    "feature_cols = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=23)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost's hyperparameters\n",
    "\n",
    "At this point, before building the model, you should be aware of the tuning parameters that XGBoost provides. Well, there are a plethora of tuning parameters for tree-based learners in XGBoost and you can read all about them [here](https://xgboost.readthedocs.io/en/latest/parameter.html#general-parameters). But the most common ones that you should know are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall parameters have been divided into 3 categories by XGBoost authors:\n",
    "\n",
    "- **General Parameters:** Guide the overall functioning\n",
    "- **Booster Parameters:** Guide the individual booster (tree/regression) at each step\n",
    "- **Learning Task Parameters:** Guide the optimization performed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Parameters\n",
    "These define the overall functionality of XGBoost.\n",
    "\n",
    "- **booster** [default=gbtree]\n",
    "Select the type of model to run at each iteration. It has 2 options:\n",
    "    - gbtree: tree-based models\n",
    "    - gblinear: linear models\n",
    "    \n",
    "- **silent** [default=0]:\n",
    "Silent mode is activated is set to 1, i.e. no running messages will be printed. It’s generally good to keep it 0 as the messages might help in understanding the model.\n",
    "\n",
    "- **nthread**  [default to maximum number of threads available if not set]\n",
    "This is used for parallel processing and number of cores in the system should be entered. If you wish to run on all cores, value should not be entered and algorithm will detect automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Booster Parameters\n",
    "Though there are 2 types of boosters, we’ll consider only tree booster here because it always outperforms the linear booster and thus the later is rarely used.\n",
    "\n",
    "- **eta [default=0.3]**\n",
    "    - Analogous to learning rate in GBM\n",
    "    - Makes the model more robust by shrinking the weights on each step\n",
    "    - Typical final values to be used: 0.01-0.2\n",
    "- **min_child_weight [default=1]**\n",
    "    - Defines the minimum sum of weights of all observations required in a child.\n",
    "    - This is similar to min_child_leaf in GBM but not exactly. This refers to min “sum of weights” of observations while GBM has min “number of observations”.\n",
    "    - Used to control over-fitting. Higher values prevent a model from learning relations which might be highly specific to the particular sample selected for a tree.\n",
    "    - Too high values can lead to under-fitting hence, it should be tuned using CV.\n",
    "- **max_depth [default=6]**\n",
    "    - The maximum depth of a tree, same as GBM.\n",
    "    - Used to control over-fitting as higher depth will allow model to learn relations very specific to a particular sample.\n",
    "    - Should be tuned using CV.\n",
    "    - Typical values: 3-10\n",
    "- **max_leaf_nodes**\n",
    "    - The maximum number of terminal nodes or leaves in a tree.\n",
    "    - Can be defined in place of max_depth. Since binary trees are created, a depth of ‘n’ would produce a maximum of 2^n leaves.\n",
    "    - If this is defined, GBM will ignore max_depth.\n",
    "- **gamma [default=0]**\n",
    "    - A node is split only when the resulting split gives a positive reduction in the loss function. Gamma specifies the minimum loss reduction required to make a split.\n",
    "    - Makes the algorithm conservative. The values can vary depending on the loss function and should be tuned.\n",
    "- **max_delta_step [default=0]**\n",
    "    - In maximum delta step we allow each tree’s weight estimation to be. If the value is set to 0, it means there is no constraint. If it is set to a positive value, it can help making the update step more conservative.\n",
    "    - Usually this parameter is not needed, but it might help in logistic regression when class is extremely imbalanced.\n",
    "    - This is generally not used but you can explore further if you wish.\n",
    "- **subsample [default=1]**\n",
    "    - Same as the subsample of GBM. Denotes the fraction of observations to be randomly samples for each tree.\n",
    "    - Lower values make the algorithm more conservative and prevents overfitting but too small values might lead to under-fitting.\n",
    "    - Typical values: 0.5-1\n",
    "- **colsample_bytree [default=1]**\n",
    "    - Similar to max_features in GBM. Denotes the fraction of columns to be randomly samples for each tree.\n",
    "    - Typical values: 0.5-1\n",
    "- **colsample_bylevel [default=1]**\n",
    "    - Denotes the subsample ratio of columns for each split, in each level.\n",
    "    - I don’t use this often because subsample and colsample_bytree will do the job for you. but you can explore further if you feel so.\n",
    "- **lambda [default=1]**\n",
    "    - L2 regularization term on weights (analogous to Ridge regression)\n",
    "    - This used to handle the regularization part of XGBoost. Though many data scientists don’t use it often, it should be explored to reduce overfitting.\n",
    "- **alpha [default=0]**\n",
    "    - L1 regularization term on weight (analogous to Lasso regression)\n",
    "    - Can be used in case of very high dimensionality so that the algorithm runs faster when implemented\n",
    "- **scale_pos_weight [default=1]**\n",
    "    - A value greater than 0 should be used in case of high class imbalance as it helps in faster convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Task Parameters\n",
    "\n",
    "These parameters are used to define the optimization objective the metric to be calculated at each step.\n",
    "\n",
    "- **objective [default=reg:linear]**\n",
    "    - This defines the loss function to be minimized. Mostly used values are:\n",
    "        - binary:logistic –logistic regression for binary classification, returns predicted probability (not class)\n",
    "        - multi:softmax –multiclass classification using the softmax objective, returns predicted class (not probabilities)\n",
    "                - you also need to set an additional num_class (number of classes) parameter defining the number of unique classes\n",
    "        - multi:softprob –same as softmax, but returns predicted probability of each data point belonging to each class.\n",
    "- **eval_metric [ default according to objective ]**\n",
    "    - The metric to be used for validation data.\n",
    "    - The default values are rmse for regression and error for classification.\n",
    "    - Typical values are:\n",
    "            - rmse – root mean square error\n",
    "            - mae – mean absolute error\n",
    "            - logloss – negative log-likelihood\n",
    "            - error – Binary classification error rate (0.5 threshold)\n",
    "            - merror – Multiclass classification error rate\n",
    "            - mlogloss – Multiclass logloss\n",
    "            - auc: Area under the curve\n",
    "- **seed [default=0]**\n",
    "    - The random number seed.\n",
    "    - Can be used for generating reproducible results and also for parameter tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tuning with Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38245219347581555"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic['Survived'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_clf = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                           colsample_bytree = 0.5, \n",
    "                           subsample = 0.5,\n",
    "                           learning_rate = 0.1,\n",
    "                           max_depth = 4, \n",
    "                           alpha = 1, \n",
    "                           scale_pos_weight= titanic['Survived'].mean(),\n",
    "                           n_estimators = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=1, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.5, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=4,\n",
       "              min_child_weight=1, missing=None, n_estimators=10000, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=0.38245219347581555,\n",
       "              seed=None, silent=None, subsample=0.5, verbosity=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_clf.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.757848\n",
      "F1: 0.635135\n"
     ]
    }
   ],
   "source": [
    "preds = xg_clf.predict(X_test)\n",
    "\n",
    "\n",
    "test_f1 = f1_score(y_test, preds)\n",
    "test_acc = accuracy_score(y_test, preds)\n",
    "\n",
    "print(\"Accuracy: %f\" % (test_acc))\n",
    "print(\"F1: %f\" % (test_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-fold Cross Validation using XGBoost\n",
    "In order to build more robust models, it is common to do a k-fold cross validation where all the entries in the original training dataset are used for both training as well as validation. XGBoost supports k-fold cross validation via the cv() method. All you have to do is specify the nfolds parameter, which is the number of cross validation sets you want to build. Also, it supports many other parameters (check out this link) like:\n",
    "\n",
    "- **num_boost_round**: denotes the number of trees you build (analogous to n_estimators)\n",
    "- **metrics:** tells the evaluation metrics to be watched during CV\n",
    "- **as_pandas**: to return the results in a pandas DataFrame.\n",
    "- **early_stopping_rounds: finishes training of the model early if the hold-out metric (\"rmse\" in our case) does not improve for a given number of rounds.\n",
    "- **seed**: for reproducibility of results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running your model, you will convert the dataset into an optimized data structure called Dmatrix that XGBoost supports and gives it acclaimed performance and efficiency gains. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelarmistead/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/michaelarmistead/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    }
   ],
   "source": [
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {\"objective\":\"binary:logistic\",\n",
    "          'colsample_bytree': 0.3,\n",
    "          'learning_rate': 0.1,\n",
    "          'max_depth': 3, \n",
    "          'alpha': 1}\n",
    "\n",
    "cv_results = xgb.cv(dtrain=data_dmatrix, \n",
    "                    params=params, \n",
    "                    nfold=5,\n",
    "                    num_boost_round=500,\n",
    "                    early_stopping_rounds=5,\n",
    "                    metrics=\"logloss\", \n",
    "                    as_pandas=True, \n",
    "                    seed=123)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-logloss-mean</th>\n",
       "      <th>train-logloss-std</th>\n",
       "      <th>test-logloss-mean</th>\n",
       "      <th>test-logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.659772</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>0.660168</td>\n",
       "      <td>0.001478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.639739</td>\n",
       "      <td>0.006761</td>\n",
       "      <td>0.640184</td>\n",
       "      <td>0.010529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.627790</td>\n",
       "      <td>0.006070</td>\n",
       "      <td>0.629019</td>\n",
       "      <td>0.010380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.614868</td>\n",
       "      <td>0.010608</td>\n",
       "      <td>0.616502</td>\n",
       "      <td>0.015193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.599252</td>\n",
       "      <td>0.010671</td>\n",
       "      <td>0.601503</td>\n",
       "      <td>0.014880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>0.372616</td>\n",
       "      <td>0.009112</td>\n",
       "      <td>0.434313</td>\n",
       "      <td>0.038028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.371920</td>\n",
       "      <td>0.009004</td>\n",
       "      <td>0.434456</td>\n",
       "      <td>0.038454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>0.371195</td>\n",
       "      <td>0.009250</td>\n",
       "      <td>0.434110</td>\n",
       "      <td>0.038592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.370798</td>\n",
       "      <td>0.009382</td>\n",
       "      <td>0.434108</td>\n",
       "      <td>0.038613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>0.370584</td>\n",
       "      <td>0.009246</td>\n",
       "      <td>0.433982</td>\n",
       "      <td>0.038632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     train-logloss-mean  train-logloss-std  test-logloss-mean  \\\n",
       "0              0.659772           0.000850           0.660168   \n",
       "1              0.639739           0.006761           0.640184   \n",
       "2              0.627790           0.006070           0.629019   \n",
       "3              0.614868           0.010608           0.616502   \n",
       "4              0.599252           0.010671           0.601503   \n",
       "..                  ...                ...                ...   \n",
       "127            0.372616           0.009112           0.434313   \n",
       "128            0.371920           0.009004           0.434456   \n",
       "129            0.371195           0.009250           0.434110   \n",
       "130            0.370798           0.009382           0.434108   \n",
       "131            0.370584           0.009246           0.433982   \n",
       "\n",
       "     test-logloss-std  \n",
       "0            0.001478  \n",
       "1            0.010529  \n",
       "2            0.010380  \n",
       "3            0.015193  \n",
       "4            0.014880  \n",
       "..                ...  \n",
       "127          0.038028  \n",
       "128          0.038454  \n",
       "129          0.038592  \n",
       "130          0.038613  \n",
       "131          0.038632  \n",
       "\n",
       "[132 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEWCAYAAACwtjr+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de3gV1dXH8e8iQQQCCAUUBLkUCiFcIqCIRQy2gBKqUi1q5UUuVqmtpSJSfHlVtFYRpXJTEbWKSNGiKNYbtkqoopVLCSAgUiXKzQuIQjBKCOv940ziSTiBAJkkJ/4+z3OezNmzZ8+aSXJWZu/JbHN3REREwlSlvAMQEZHKT8lGRERCp2QjIiKhU7IREZHQKdmIiEjolGxERCR0SjYiFYSZzTCzm8o7DpEwmP7PRuKdmWUBJwJ5UcU/cvdtx9BmGvCEuzc5tujik5k9Bmxx9/8r71ikctCVjVQWP3P3pKjXUSea0mBmieW5/2NhZgnlHYNUPko2UqmZ2Rlm9paZfWlmq4Irlvx1Q81svZntMbMPzezqoLwm8DLQ2Myyg1djM3vMzG6P2j7NzLZEvc8ysz+Y2Wpgr5klBts9Y2afm9kmM/vdIWItaD+/bTMbY2afmdl2M7vQzPqZ2ftm9oWZ/W/UtuPN7Gkzeyo4nv+YWaeo9clmlhGch7Vmdn6R/T5gZi+Z2V5gOHA5MCY49r8H9caa2QdB++vMbEBUG0PM7E0zu8fMdgXHel7U+npm9qiZbQvWPxe1rr+ZZQaxvWVmHUv8DZa4oWQjlZaZnQy8CNwO1ANGA8+YWYOgymdAf6A2MBS418w6u/te4Dxg21FcKV0GpAMnAAeAvwOrgJOBnwC/N7O+JWzrJOD4YNubgYeAQUAX4CzgZjNrGVX/AmBecKx/BZ4zs6pmVjWI41WgIXAtMMfM2kRt+0vgT0At4HFgDjAxOPafBXU+CPZbB7gVeMLMGkW10Q3YANQHJgKPmJkF62YDNYCUIIZ7AcysM/AX4GrgB8CDwPNmVq2E50jihJKNVBbPBX8Zfxn1V/Mg4CV3f8ndD7j7P4DlQD8Ad3/R3T/wiMVEPozPOsY4prr7ZnfPAU4DGrj7be6+z90/JJIwLi1hW7nAn9w9F3iSyIf4FHff4+5rgbVA9FXACnd/Oqj/ZyKJ6ozglQRMCOJ4HXiBSGLMt8DdlwTn6ZtYwbj7PHffFtR5CtgInB5V5SN3f8jd84BZQCPgxCAhnQeMcPdd7p4bnG+AXwEPuvs77p7n7rOAb4OYpRKJ235lkSIudPd/FilrBvzCzH4WVVYVWAQQdPPcAvyIyB9eNYA1xxjH5iL7b2xmX0aVJQBvlLCtncEHN0BO8PXTqPU5RJLIQft29wNBF1/j/HXufiCq7kdErphixR2TmQ0GRgHNg6IkIgkw3ydR+/86uKhJInKl9YW774rRbDPgCjO7NqrsuKi4pZJQspHKbDMw291/VXRF0E3zDDCYyF/1ucEVUX63T6zbNPcSSUj5TopRJ3q7zcAmd299NMEfhab5C2ZWBWgC5Hf/NTWzKlEJ5xTg/ahtix5vofdm1ozIVdlPgLfdPc/MMvnufB3KZqCemZ3g7l/GWPcnd/9TCdqROKZuNKnMngB+ZmZ9zSzBzI4PBt6bEPnruRrwObA/uMrpE7Xtp8APzKxOVFkm0C8Y7D4J+P1h9r8U2B3cNFA9iKG9mZ1WakdYWBcz+3lwJ9zviXRH/Rt4h0iiHBOM4aQBPyPSNVecT4Ho8aCaRBLQ5xC5uQJoX5Kg3H07kRsu7jezukEMPYPVDwEjzKybRdQ0s3Qzq1XCY5Y4oWQjlZa7byYyaP6/RD4kNwM3AFXcfQ/wO+BvwC4iA+TPR237HjAX+DAYB2pMZJB7FZBFZHznqcPsP4/Ih3oqsAnYATxMZIA9DAuAS4gcz/8APw/GR/YB5xMZN9kB3A8MDo6xOI8A7fLHwNx9HTAJeJtIIuoALDmC2P6HyBjUe0RuzPg9gLsvJzJuMz2I+7/AkCNoV+KE/qlTpBIws/FAK3cfVN6xiMSiKxsREQmdko2IiIRO3WgiIhI6XdmIiEjo9H82RZxwwgneqlWr8g6jxPbu3UvNmjXLO4wSU7zhiqd44ylWULyHs2LFih3u3qC49Uo2RZx44oksX768vMMosYyMDNLS0so7jBJTvOGKp3jjKVZQvIdjZh8dar260UREJHRKNiIiEjolGxERCZ2SjYiIhE7JRkREQqdkIyIioVOyERGR0CnZiIhI6JRsREQkdEo2IiISOiUbEREJnZKNiIiETslGRERCp2QjIiKhU7IREZHQKdmIiEjolGxERCqZYcOGMWDAANq3b19QdtNNN9GxY0dSU1Pp06cP27ZtA2DXrl0MGDCAjh07cvrpp/Puu+8WbPPKK6/Qpk0bWrVqxYQJEwrKhw8fTqdOnejYsSMXX3wx2dnZh42pwicbM8szs8yoV/PyjklEpCIbMmQId911V6GyG264gdWrV5OZmUn//v257bbbALjjjjtITU1l9erVPP7444wcORKAvLw8fvOb3/Dyyy+zbt065s6dy7p16wC49957WbVqFatXr+aUU05h+vTph40pHqaFznH31CPdyMwS3D3viHeWm0fzsS8e6Wbl5voO+xmieEOjeMMTT7FC/MSbNSGdnj17Fly55Ktdu3bB8t69ezEzANatW8eNN94IQNu2bcnKyuLTTz/lww8/pFWrVrRs2RKASy+9lAULFtCuXbuCttydnJycgrYOpcJf2cRiZs3N7A0z+0/wOjMoTzOzRWb2V2BNUDbIzJYGV0UPmllCuQYvIlJOxo0bR9OmTZkzZ07BlU2nTp2YP38+AEuXLuWjjz5iy5YtbN26laZNmxZs26RJE7Zu3VrwfujQoZx00km89957XHvttYfdt7l7KR9O6TKzPILEAWxy9wFmVgM44O7fmFlrYK67dzWzNOBFoL27bzKzZGAi8HN3zzWz+4F/u/vjRfZxFXAVQP36DbrcPPmhMjq6Y3didfg0p7yjKDnFG654ijeeYoX4ibfDyXUA+OCDD7j99tt59NFHD6ozZ84c9u3bx9ChQ9m7dy/Tp09n48aNtGzZko8//pjRo0ezZcsWli1bxg033ADAq6++ynvvvcfvfve7gnby8vKYOnUqbdu2ZeLEiSvcvWtxccVrN1pVYLqZpQJ5wI+i1i11903B8k+ALsCy4DKvOvBZ0R24+0xgJsApLVv5pDXxcFoiru+wH8UbHsUbnniKFeIn3qzL0wD45JNPqFmzJmlpaQfVadGiBenp6cyaNQuA9PR0INIt1qJFCwYOHMjatWt5++23C7Z/++23Oe200w5qLzExkbvvvvuwcVX8MxfbdcCnQCciXYHfRK3bG7VswCx3v7GkDVevmsCGCemlEmRZyMjIKPjhigeKN1zxFG88xQrxF29RGzdupHXr1gA8//zztG3bFoAvv/ySGjVqcNxxx/Hwww/Ts2dPateuzWmnncbGjRvZtGkTJ598Mk8++SR//etfcXc++OADWrVqhbvz97//nbZt2/Lii4cez4rXZFMH2OLuB8zsCqC4cZjXgAVmdq+7f2Zm9YBa7v5RmUUqIlLGLrvsMl599VV2795NkyZNuPXWW3nppZfYsGEDVapUoVmzZsyYMQOA9evXM3jwYBISEmjXrh2PPPIIELlimT59On379iUvL49hw4aRkpLCgQMHuOKKK9i9ezfuTqdOnXjggQeYNGnSIWOK12RzP/CMmf0CWEThq5kC7r7OzP4PeNXMqgC5wG8AJRsRqbTmzp1LRkZGoS6v4cOHx6zbvXt3Nm7cGHNdv3796NevX6GyKlWqsGTJkiOOqcInG3dPilG2EegYVXRjUJ4BZBSp+xTwVHgRiojI4cTlrc8iIhJflGxERCR0SjYiIhI6JRsREQmdko2IiIROyUZEREKnZCMiIqFTshERkdAp2YiISOiUbEREJHRKNiIiEjolGxERCZ2SjYhIYNiwYTRs2JD27dsXlM2bN4+UlBTOOeccli9fXqj+6tWr6d69OykpKXTo0IFvvolMrXXuuefSqVMnUlJSGDFiBHl5eQBkZmZyxhlnkJqaSteuXVm6dGnZHVw5i7tkY2YDzMzNrG15xyIilcuQIUN45ZVXCpW1b9+e+fPn07Fjx0Ll+/fvZ9CgQcyYMYO1a9eSkZFB1apVAfjb3/7GqlWrePfdd/n888+ZN28eAGPGjOGWW24hMzOT2267jTFjxpTNgVUAFX6KgRguA94ELgXGl3bjObl5NB976BnnKpLrO+xniOINjeINT0WLNWtCOj179iQrK6tQeXJycsz6r776Kh07dqRTp04A/OAHPyhYV7t2bSCSkPbt20cwLT1mxu7duwH46quvaNy4cWkfRoUVV1c2ZpYE/BgYTiTZYGZVzOx+M1trZi+Y2UtmdnGwrouZLTazFWa20MwalWP4IlKJvP/++5gZffv2pXPnzkycOLHQ+r59+9KwYUNq1arFxRdfDMDkyZO54YYbaNq0KaNHj+bOO+8sj9DLRbxd2VwIvOLu75vZF2bWGWgJNAc6AA2B9cBfzKwqMA24wN0/N7NLgD8Bw4o2amZXAVcB1K/fgJs77C+TgykNJ1aP/IUYLxRvuOIp3ooWa0ZGBgCffPIJe/fuLXifLy8vjxUrVpCdnQ3Ahg0b+Oc//8mMGTOoVq0a119/PQkJCXTp0gWAG2+8kX379nH77bdz77330rVrV6ZOncrw4cM5++yzWbRoET//+c8PO53y0crOzj7oGMpTvCWby4DJwfKTwfuqwDx3PwB8YmaLgvVtgPbAP4JL2ARge6xG3X0mMBPglJatfNKa+Dkt13fYj+INj+INT0WLNevytMjXrCxq1qxZaEploCCRdO3aFYgkpZycHC644AIAli1bxoEDBw7abvv27SxbtozRo0dzwQUX8Mwzz2BmnH322dx7770H1S8tRaeFLm8V5zt9GGb2A+AcoL2ZOZHk4cCzxW0CrHX37keyn+pVE9gwIf2YYi1LGRkZBb8k8UDxhiue4o2nWGPp27cvEydO5Ouvv+a4445j8eLFXHfddWRnZ7Nnzx4aNWrE/v37eemllzjrrLMAaNy4MYsXLyYtLY3XX3+d1q1bl/NRlJ24STbAxcDj7n51foGZLQZ2ABeZ2SygAZAG/BXYADQws+7u/nbQrfYjd19b9qGLSDy47LLLyMjIYMeOHTRp0oRbb72VevXqce211/LZZ5+Rnp5OamoqCxcupG7duowaNYrTTjsNM6Nfv36kp6fz6aefcv755/Ptt9+Sl5fHOeecw4gRIwB46KGHGDlyJPv37+f4449n5syZ5XzEZSeeks1lwIQiZc8AycAW4F3gfeAd4Ct33xfcKDDVzOoQOdbJgJKNiMQ0d+7cmOUDBgyI2S01aNAgBg0aVKjsxBNPZNmyZTHb6dGjBytWrCiVWONN3CQbd0+LUTYVInepuXt20NW2FFgTrM8EepZlnCIicrC4STaH8YKZnQAcB/zR3T8p74BEROQ7lSLZxLrqERGRiiOu/qlTRETik5KNiIiETslGRERCp2QjIiKhU7IREZHQKdmIiEjolGxERCR0SjYiIhI6JRsREQmdko2E5ptvvuH000+nU6dOpKSkcMsttwBw1llnkZqaSmpqKo0bN+bCCy8EYM6cOXTs2JGOHTty5plnsmrVKiAySVV+/dTUVGrXrs3kyZOL3a+IVDzl+rgaM8sj8tDMRCIzbF7h7l8XU3c8kO3u95RdhHIsqlWrxuuvv05SUhK5ubn06NGDE088kTfeeKOgzkUXXVQw+VSLFi1YvHgxdevW5eWXX+aqq67inXfeoU2bNmRmZgKR2RJPPvlkBgwYUC7HJCJHp7yfjZbj7qkAZjYHGAH8uVwDys2j+dgXyzOEI3J9h/0MqYDxZk1Ix8xISkoCIDc3l9zc3EJ19uzZw+uvv86jjz4KwJlnnlmw7owzzmDLli0Htfvaa6/xwx/+kGbNmoUYvYiUtorUjfYG0ArAzAab2WozW2Vms4tWNLNfmdmyYP0zZlYjKP+Fmb0blP8rKEsxs6Vmlhm0+f2ZGq8CyMvLIzU1lYYNG9K7d2/atWtXsO7ZZ5/lJz/5CbVr1z5ou0ceeYTzzjvvoPInn3ySyy67LNSYRaT0VYhkY2aJwHnAGjNLAcYB57h7J2BkjE3mu/tpwfr1wPCg/Gagb1B+flA2ApgSXEF1JTLRmpSRhIQEMjMz2bJlC0uXLmXTpk0F6+bOnRszcSxatIhHHnmEu+66q1D5vn37eP755/nFL34RetwiUrrKuxutupllBstvAI8AVwNPu/sOAHf/IsZ27c3sduAEIAlYGJQvAR4zs78B84Oyt4FxZtaESJLaWLQxM7sKuAqgfv0G3Nxhf6kcXFk4sXqkK62iycjIOKisefPmvPHGG7Ro0YKvvvqKt956i+uuu65Q3Q8++ICbb76ZCRMmsGbNmkLbv/nmm7Ro0YL169ezfv36kI8gIjs7O+axVFTxFG88xQqK91iVd7IpGLPJZ2YG+GG2ewy40N1XmdkQIA3A3UeYWTcgHcg0s1R3/6uZvROULTSzK9399ejG3H0mMBPglJatfNKa8j4tJXd9h/1UxHizLk/j888/p2rVqpxwwgnk5ORw00030a9fP9LS0pgxYwYXXnghffr0Kdjm448/5sorr2TevHmFxm/yzZgxg2uuueagqXnDFGsq4IosnuKNp1hB8R6rivcpBa8Bz5rZve6+08zqxbi6qQVsN7OqwOXAVgAz+6G7vwO8Y2Y/A5qaWR3gQ3efamYtgY7A6xSjetUENkxID+O4QpGRkUHW5WnlHUZM27dv54orriAvL48DBw4wcOBAunfvDkTGXsaOHVuo/m233cbOnTu55pprAEhMTGT58uUAfP311/zjH//gwQcfLNuDEJFSUeGSjbuvNbM/AYuDW6NXAkOKVLsJeAf4iMit07WC8ruDGwCMSNJaBYwFBplZLvAJcFvoByEAdOzYkZUrVxYqy7+sj3V5//DDD/Pwww/HbKtGjRrs3LmztEMUkTJSrsnG3ZOKKZ8FzCpSNj5q+QHggRjb/TxGc3cGLxERKScV4m40ERGp3JRsREQkdEo2IiISOiUbEREJnZKNiIiETslGRERCp2QjIiKhU7IREZHQKdmIiEjolGxERCR0SjYiIhI6JRsREQmdko0UsnnzZnr16kVycjIpKSlMmTIFgMzMTM444wxSU1Pp2rUrS5cuLbTdsmXLSEhI4Omnny4oS0hIIDU1ldTUVM4//3xE5Purwk0xUBrMLA0Y7e79yzuWeJOYmMikSZPo3Lkze/bsoUuXLvTu3ZsxY8Zwyy23cN555/HSSy8xZsyYgmkC8vLy+MMf/kDfvn0LtVW9enUyMzNj7EVEvm8qZbI5Fjm5eTQf+2J5h1Fi13fYz5BSijdrQjqNGjWiUaNGANSqVYvk5GS2bt2KmbF7924AvvrqKxo3blyw3bRp07joootYtmxZqcQhIpVPhU02ZtYceAV4EziDyERojwK3Ag2JzNAJMBmoDuQAQ919Q5F2agLTgA5Ejne8uy8I/wjiX1ZWFitXrqRbt25MnjyZvn37Mnr0aA4cOMBbb70FwNatW3n22Wd5/fXXD0o233zzDV27diUxMZGxY8dy4YUXlsdhiEgFYO5e3jHEFCSb/wKnAmuBZUQSznDgfGAoMBj42t33m9lPgV+7+0XR3Whmdgewzt2fMLMTgKXAqe6+N2pfVwFXAdSv36DLzZMfKqOjPHYnVodPc0qnrQ4n1ylYzsnJYeTIkQwaNIiePXsydepUOnXqxNlnn82iRYt44YUXmDRpEuPHj2fgwIG0a9eOCRMm0L17d84++2wAduzYQf369dm2bRujRo1i0qRJ1KlTh6SkmHPmVUjZ2dmKNyTxFCso3sPp1avXCnfvWtz6ip5s/uHurYP3jwML3X2OmbUE5gM/A6YCrQEHqrp72yLJZjlwPLA/aLoe0Nfd18fa7yktW3mVgVPCO7BSdn2H/UxaUzoXqFkT0gHIzc2lf//+9O3bl1GjRgFQp04dvvzyS8wMd6dOnTrs3r2bFi1akP8ztGPHDmrUqMHMmTMPuooZMmQI/fv3p379+qSlpZVKvGUhIyND8YYknmIFxXs4ZnbIZFPR70b7Nmr5QNT7A0S6xP4ILHL39kQSz/Ex2jDgIndPDV6nFJdoBNyd4cOHk5ycXJBoABo3bszixYsBeP3112ndujUAmzZtIisri6ysLC6++GLuv/9+LrzwQnbt2sW330a+XTt27GDJkiW0a9eu7A9IRCqEI/6T2MzqAk3dfXUI8RypOsDWYHlIMXUWAtea2bXu7mZ2qruvLK7B6lUT2BD8hR8PMjIyyLo8rdTaW7JkCbNnz6ZDhw6kpqYCcMcdd/DQQw8xcuRI9u/fz/HHH8/MmTMP2c769eu5+uqrqVKlCgcOHGDs2LG0a9eOzz77rNRiFZH4UaJkY2YZRMZJEoFM4HMzW+zuow65YfgmArPMbBTwejF1/kjkJoLVZmZAFqBboovRo0cPiutaXbFixSG3feyxxwqWzzzzTNasWVOaoYlIHCvplU0dd99tZlcCj7r7LWYW6pWNu2cB7aPeDylm3Y+iNrspWJ8BZATLOcDVIYYqIiKHUdIxm0QzawQMBF4IMR4REamESppsbiMy9vGBuy8L7gbbGF5YIiJSmZSoG83d5wHzot5/CFwUVlAiIlK5lOjKxsx+ZGavmdm7wfuOZvZ/4YYmIiKVRUm70R4CbgRyAYLbni8NKygREalcSppsarj70iJl+2PWFBERKaKkyWaHmf2QyCNhMLOLge2hRSUiIpVKSf/P5jfATKCtmW0FNvHdU5dFREQO6bDJxsyqAF3d/afB4/qruPue8EMTEZHK4rDdaO5+APhtsLxXiUZERI5UScds/mFmo82sqZnVy3+FGpmIiFQaJR2zGRZ8/U1UmQMtSzccERGpjEp0ZePuLWK8lGjiwObNm+nVqxfJycmkpKQwZUpkYribbrqJjh07kpqaSp8+fdi2bRsA7733Ht27d6datWrcc889hdr68ssvufjii2nbti3Jycm8/fbbZX48IhKfSjrFwOBY5e7+eGkGY2bjgF8CeUQmSLsa+BXwZ3dfZ2bZ7n7QPKdmdgYwBagWvJ5y9/GlGVu8SkxMZNKkSXTu3Jk9e/bQpUsXevfuzQ033MAf//hHAKZOncptt93GjBkzqFevHlOnTuW55547qK2RI0dy7rnn8vTTT7Nv3z6+/vrrsj4cEYlTJe1GOy1q+XjgJ8B/gFJLNmbWncg8M53d/Vszqw8c5+5XlmDzWcBAd19lZglAm6ONIyc3j+ZjXzzazcvc9R32M6SYeLMmpNOoUSMaNWoEQK1atUhOTmbr1q2FZs3cu3cvkal+oGHDhjRs2JAXXyzc5u7du/nXv/5VMGfNcccdx3HHHRfCEYlIZVTSB3FeG/3ezOoAs0s5lkbADnf/NtjnjmBfGcBod18evJ8E9AJ2AZe6++dAQ4J/MnX3PGBdUHc88EPgZKApMNHdHyrluONGVlYWK1eupFu3bgCMGzeOxx9/nDp16rBo0aJDbvvhhx/SoEEDhg4dyqpVq+jSpQtTpkyhZs2aZRG6iMQ5K25WxkNuZFYVWO3uyaUWiFkS8CZQA/gnka6wxdHJxswcGOTuc8zsZqChu/82WL6OyIRprwCz3P2bINkMAM4AagIrgW7uvq3Ivq8CrgKoX79Bl5snx08+OrE6fJoTe12Hk+sULOfk5DBy5EgGDRpEz549C9WbM2cO+/btY+jQoQVljz32GNWrV+eSSy4BYMOGDVxzzTVMmzaNdu3aMW3aNGrWrMmwYcM4EtnZ2SQlHdQTWmEp3vDEU6ygeA+nV69eK9y9a3HrSzpm83eCR9UQuamgHVFTDpQGd882sy7AWUSuXJ4ys7FFqh0AngqWnwDmB9veZmZzgD5ExnwuA9KCeguC2TpzzGwRcDpQaEDC3WcSeUICp7Rs5ZPWlLR3sfxd32E/xcWbdXkaALm5ufTv358RI0YwatTBM3m3aNGC9PR0Zs2aVVCWkZFBUlISaWmRNtq2bcudd97JNddcA0BCQgITJkwoWF9SGRkZR7xNeVK84YmnWEHxHquSfqpG35a0H/jI3beUdjBBF1gGkGFma4ArDrdJ1LYfAA+Y2UPA52b2g6J1inlfSPWqCWyYkH5EcZenjIyMgqQSi7szfPhwkpOTCyWajRs30rp1awCef/552rZte8j9nHTSSTRt2pQNGzbQpk0bXnvttULjPiIih1LSZNPP3f8QXWBmdxUtOxZm1gY44O75M4CmAh8B7aOqVQEuBp4kcgXzZrBtOvCSR/oEWxO5m+3LYJsLzOxOIt1oaUDRq6VKbcmSJcyePZsOHTqQmpoKwB133MEjjzzChg0bqFKlCs2aNWPGjBkAfPLJJ3Tt2pXdu3dTpUoVJk+ezLp166hduzbTpk3j8ssvZ9++fbRs2ZJHH320PA9NROJISZNNb6BoYjkvRtmxSAKmmdkJRK6e/ktkHOXpqDp7gRQzWwF8BVwSlP8PcK+ZfR1se7m75wV3WC0FXgROAf5YdLymsuvRowexxuX69esXs/5JJ53Eli2xL1pTU1NZvnx5qcYnIt8Ph0w2ZvZr4BqgpZmtjlpVC1hSmoG4+wrgzBir0qLq5I923VRk20NN5Pa+u191zAGKiMhRO9yVzV+Bl4E7Kdz9tMfdvwgtKhERqVQOmWzc/Ssi3VWXAZhZQyL/1JlkZknu/nH4IR49PUVARKRiKNGz0czsZ2a2kcikaYuBLCJXPCIiIodV0ikGbifyj5Hvu3sLIo+rKdUxGxERqbxKmmxy3X0nUMXMqrj7IiK3JouIiBxWSW99/jJ4nMwbwBwz+4zILcYiIiKHVdIrmwuAr4HfE3n22AfAz8IKSkREKpeSPvV5r5k1A1q7+ywzqwEkhBuaiIhUFiW9G+1XRP6T/8Gg6GSKPMxSRESkOCXtRvsN8GNgN0Dw/LKGYQUlIiKVS0mTzbfuvi//jZklcpinJ4uIiOQrabJZbGb/C1Q3s95E5rL5e3hhiYhIZY/79pAAABbySURBVFLSZDMW+BxYA1wNvAT8X1hBydHZvHkzvXr1Ijk5mZSUFKZMmQLAvHnzSElJoUqVKgc9tfnOO++kVatWtGnThoULFxZal5eXx6mnnkr//v3L7BhEpHI63FOfT3H3j939APBQ8Io7ZjaOyPw3eURm+7za3d8p36hKX2JiIpMmTaJz587s2bOHLl260Lt3b9q3b8/8+fO5+uqrC9Vft24dTz75JGvXrmXbtm389Kc/5f333ychIXKj4ZQpU0hOTmb37t3lcTgiUokc7tbn54DOAGb2jLtfFH5IpcvMugP9gc7u/q2Z1QeOK65+Tm4ezce+WGbxHavrO+xnSBBv1oR0GjVqBECtWrVITk5m69at9O7dO+a2CxYs4NJLL6VatWq0aNGCVq1asXTpUrp3786WLVt48cUXGTduHH/+85/L7HhEpHI6XDeaRS23DDOQEDUCdrj7twDuvuP7MIFaVlYWK1eupFu3bsXW2bp1K02bNi1436RJE7Zu3QrA73//eyZOnEiVKiXtaRURKd7hrmy8mOV48ipws5m9D/wTeMrdF0dXMLOriMwKSv36Dbi5Q/w8iefE6pGrG4CMjAwAcnJyGDlyJFdeeSX/+c9/Cup++eWXrFixguzsbAC2bNnC+vXrC7bbvn07a9euZePGjeTm5rJnzx4yMzPZuXNnQZ1jlZ2dXWptlQXFG554ihUU77E6XLLpZGa7iVzhVA+WCd67u9cONbpS4O7ZZtYFOAvoBTxlZmPd/bGoOjOBmQCntGzlk9aU9JFx5e/6DvvJjzfr8jRyc3Pp378/I0aMYNSoUYXqnnDCCXTp0oWuXbsC8PbbbwOQlpYGRG4W6NOnD88//zwrVqxgyJAhfPPNN+zevZuHH36YJ5544pjjzcjIKNhfPFC84YmnWEHxHqvDTZ5WKR5J4+55QAaQYWZrgCuAx2LVrV41gQ0T0ssuuGOUkZFB1uVpALg7w4cPJzk5+aBEE8v555/PL3/5S0aNGsW2bdvYuHEjp59+Ot27d+fOO+8saP+ee+4plUQjIt9f8fMn/FEyszbAgeCpBxCZGuGjcgwpNEuWLGH27Nl06NCB1NTIDBB33HEH3377Lddeey2ff/456enppKamsnDhQlJSUhg4cCDt2rUjMTGR++67r+BONBGR0lTpkw2QBEwzsxOITIvwX4LxmcqmR48euMceWhswYEDM8nHjxjFu3Lhi20xLS6tQl+IiEp8qfbJx9xXAmeUdh4jI95nuaxURkdAp2YiISOiUbEREJHRKNiIiEjolGxERCZ2SjYiIhE7JRkREQqdkIyIioVOyERGR0CnZiIhI6JRsREQkdEo2cWDYsGE0bNiQ9u3bFyqfNm0agwcPJiUlhTFjxhSU33nnnbRq1Yo2bdqwcOFCADZv3kyvXr1ITk4mJSWFKVOmlOkxiMj3W4VJNmaWZ2aZZvaumc0zsxql0OYQM5teGvGVpyFDhvDKK68UKlu0aBELFizg4YcfZu3atYwePRqAdevW8eSTT7J27VpeeeUVrrnmGvLy8khMTGTSpEmsX7+ef//739x3332sW7euPA5HRL6HKtJTn3PcPRXAzOYAI4A/l2RDM0sIJkg79iBy82g+9sXSaKpUZE1Ip2fPnmRlZRUqf+CBBxg7diyJiZFvYcOGDQFYsGABl156KdWqVaNFixa0atWKpUuX0r17dxo1agRArVq1SE5OZuvWrbRr165Mj0dEvp8qzJVNEW8ArQDM7DkzW2Fma82sYB4aM8s2s9vM7B2gu5mdZmZvmdkqM1tqZrWCqo3N7BUz22hmE8vhWELx/vvv88Ybb/DrX/+as88+m2XLlgGwdetWmjZtWlCvSZMmbN26tdC2WVlZrFy5km7dupVpzCLy/VWRrmwAMLNE4Dwgv99omLt/YWbVgWVm9oy77wRqAu+6+81mdhzwHnCJuy8zs9pATrB9KnAq8C2wwcymufvmMj2oEOzfv59du3Zx//33U7NmTQYOHMiHH34Yc/I0MytYzs7O5qKLLmLy5MnUrl27LEMWke+xipRsqptZZrD8BvBIsPw7M8ufZrIp0BrYCeQBzwTlbYDt7r4MwN13Q8GH7Gvu/lXwfh3QDCiUbIIrpqsA6tdvwM0d9pf6wR2tjIwMAD755BP27t1b8L5GjRq0bNmSvXv3Ymbs27ePBQsWsG/fPhYvXkyTJk0AWL16NZ07dyYjI4P9+/dz44030q1bN+rVq1fQVlnKzs4ul/0eLcUbnniKFRTvsapIyaZgzCafmaUBPwW6u/vXZpYBHB+s/iZqnMaA2PMhR65o8uUR45jdfSYwE+CUlq180pqKc1qyLk+LfM3KombNmgVTNA8bNoxt27aRlJRE48aNqVKlChdccAGtW7fml7/8JdOnT2fbtm3s3LmTESNGUKVKFa644gp+/OMfM3ny5HI7noyMjLiaZlrxhieeYgXFe6wqzqdqbHWAXUGiaQucUUy994iMzZwWdKPV4rtutCNSvWoCGyakH2W44bjsssvIyMhgx44dNGnShFtvvZVhw4YxbNgwZs+eTd26dZk1axZmRkpKCgMHDqRdu3YkJiZy3333kZCQwJtvvsns2bPp0KEDqamRnH7HHXfQr1+/cj46Efk+qOjJ5hVghJmtBjYA/45Vyd33mdklwLRgbCeHyBVRpTB37tyY5U888UTMv17GjRvHuHHjCpX16NEj5niOiEhZqDDJxt2TYpR9S+RmgcPWD8Zril75PBa88uv0P9Y4RUTkyFXUW59FRKQSUbIREZHQKdmIiEjolGxERCR0SjYiIhI6JRsREQmdko2IiIROyUZEREKnZCMiIqFTshERkdAp2YiISOiUbEREJHRKNkdg8+bN9OrVi+TkZFJSUpgyZQoA48eP5+STTyY1NZXU1FReeumlQtt9/PHHJCUlcc8995RH2CIi5a7CPPU5DGbWBLgPaAckAC8B1wdPkz5iiYmJTJo0ic6dO7Nnzx66dOlC7969AbjuuusYPXp0zO2uu+46zjsv5sOrRUS+FyptsrHInNDzgQfc/QIzSyAyG+dEYGRx2+Xk5tF87IsHlWdNSKdRo0Y0atQIgFq1apGcnMzWrVsPGcdzzz1Hy5YtqVmz5tEfjIhInKvM3WjnEJk6+lGAYArp64DBZnbQ3DlHKisri5UrV9KtWzcApk+fTseOHRk2bBi7du0CYO/evdx1113ccsstx7o7EZG4ZpV19kYz+x3Qwt2vK1K+Ehjq7plRZVcBVwHUr9+gy82THzqovQ4n1ylYzsnJYeTIkQwaNIiePXvyxRdfUKdOHcyMv/zlL+zcuZM//OEPPPDAA7Rt25ZevXrx2GOPUb16dS655JJSPc7s7GySko45d5YZxRuueIo3nmIFxXs4vXr1WuHuXYut4O6V8kWkq+zPMcozgdTitmva4ofe7A8vHPTKt2/fPu/Tp49PmjTJY9m0aZOnpKS4u3uPHj28WbNm3qxZM69Tp47XrVvXp02bFnO7o7Vo0aJSbS9sijdc8RRvPMXqrngPB1juh/hMrrRjNsBa4KLoAjOrDZwIbChuo+pVE9gwIT3mOndn+PDhJCcnM2rUqILy7du3F4zlPPvss7Rv3x6AN954o6DO+PHjSUpK4re//e3RHo+ISNyqzMnmNWCCmQ1298eDGwQmAdPdPedoGlyyZAmzZ8+mQ4cOpKamAnDHHXcwd+5cMjMzMTOaN2/Ogw8+WHpHISJSCVTaZOPubmYDgPvM7CagAfCUu//paNvs0aNHfldcIf369TvstuPHjz/a3YqIxL3KfDca7r7Z3c9399ZAP+BcM+tS3nGJiHzfVNorm6Lc/S2gWXnHISLyfVSpr2xERKRiULIREZHQKdmIiEjolGxERCR0SjYiIhI6JRsREQmdko2IiIROyUZEREKnZCMiIqFTshERkdAp2YiISOi+N89GO1rNmzenVq1aJCQkkJiYyPLly1m1ahUjRowgOzub5s2bM2fOHGrXrl3eoYqIVFiV7srGzN4q7TYXLVpEZmYmy5cvB+DKK69kwoQJrFmzhgEDBnD33XeX9i5FRCqVSpds3P3MY9k+JzeP5mNfPGSdDRs20LNnTwB69+7NM888cyy7FBGp9EJJNmb2RzMbGfX+T2Y20szuNrN3zWyNmV0SrEszsxei6k43syHBcpaZ3Wpm/wm2aRuUNzCzfwTlD5rZR2ZWP1iXHdVuhpk9bWbvmdkcM7OjOBb69OlDly5dmDlzJgDt27fn+eefB2DevHls3rz5KM+UiMj3g8WaefKYGzVrDsx3985mVgXYCIwBRgDnAvWBZUA3oA0w2t37B9tOB5a7+2NmlgVMcvdpZnYN0NndrwzqbHX3O83sXOBloIG77zCzbHdPMrM0YAGQAmwDlgA3uPubMeK9CrgKoH79Bl1unvwQHU6uA8COHTuoX78+u3btYvTo0fzud7+jbt26TJs2ja+++oof//jHzJ8/nwULFpT6eSyJ7OxskpKSymXfR0Pxhiue4o2nWEHxHk6vXr1WuHvX4taHcoOAu2eZ2U4zOxU4EVgJ9ADmunse8KmZLQZOA3Yfprn5wdcVwM+D5R7AgGBfr5jZrmK2XeruWwDMLBNoDhyUbNx9JjAT4JSWrXzSmkSyLk87qLFVq1aRm5vL4MGDGTx4MADvv/8+a9euJS3t4PplISMjo9z2fTQUb7jiKd54ihUU77EKc8zmYWAIMBT4C1BcF9b+InEcX2T9t8HXPL5LjiXtDvs2ajl6+2JVr5pA1oR0APbu3cuePXsKll999VXat2/PZ599BsCBAwe4/fbbGTFiRAnDERH5fgoz2TxLpMvsNGAh8C/gEjNLMLMGQE9gKfAR0M7MqplZHeAnJWj7TWAggJn1AeqGED+ffvopPXr0oFOnTpx++umkp6dz7rnnMnfuXH70ox/Rtm1bGjduzNChQ8PYvYhIpRHa/9m4+z4zWwR86e55ZvYs0B1YBTgwxt0/ATCzvwGriYztrCxB87cCc4ObDBYD24E9pX0MLVu2ZNWqVQeVjxw5kpEjR8bYQkREYgkt2QQ3BpwB/ALAI3ci3BC8CnH3MURuICha3jxqeTmQFrz9Cujr7vvNrDvQy92/DeolBV8zgIyo7X977EclIiJHI5RkY2btgBeAZ919Ywi7OAX4W5DQ9gG/CmEfIiJSSsK6G20d0DKMtoP2NwKnhtW+iIiUrkr3BAEREal4lGxERCR0SjYiIhI6JRsREQmdko2IiIROyUZEREKnZCMiIqFTshERkdAp2YiISOiUbEREJHRKNiIiEjolGxERCZ2SjYiIhE7JRkREQmeROc0kn5ntATaUdxxHoD6wo7yDOAKKN1zxFG88xQqK93CauXuD4laGNlNnHNvg7l3LO4iSMrPlijc8ijc88RQrKN5jpW40EREJnZKNiIiETsnmYDPLO4AjpHjDpXjDE0+xguI9JrpBQEREQqcrGxERCZ2SjYiIhE7JJoqZnWtmG8zsv2Y2tpxiaGpmi8xsvZmtNbORQXk9M/uHmW0MvtYNys3MpgYxrzazzlFtXRHU32hmV4Qcd4KZrTSzF4L3LczsnWDfT5nZcUF5teD9f4P1zaPauDEo32BmfUOM9QQze9rM3gvOc/eKfH7N7LrgZ+FdM5trZsdXpPNrZn8xs8/M7N2oslI7n2bWxczWBNtMNTMLId67g5+H1Wb2rJmdELUu5nkr7vOiuO9NacUatW60mbmZ1Q/el/u5PSR31ysybpUAfAC0BI4DVgHtyiGORkDnYLkW8D7QDpgIjA3KxwJ3Bcv9gJcBA84A3gnK6wEfBl/rBst1Q4x7FPBX4IXg/d+AS4PlGcCvg+VrgBnB8qXAU8Fyu+CcVwNaBN+LhJBinQVcGSwfB5xQUc8vcDKwCagedV6HVKTzC/QEOgPvRpWV2vkElgLdg21eBs4LId4+QGKwfFdUvDHPG4f4vCjue1NasQblTYGFwEdA/Ypybg95LGE1HG+v4IQvjHp/I3BjBYhrAdCbyFMNGgVljYj88ynAg8BlUfU3BOsvAx6MKi9Ur5RjbAK8BpwDvBD84O6I+uUtOLfBL0j3YDkxqGdFz3d0vVKOtTaRD28rUl4hzy+RZLM5+KBIDM5v34p2foHmFP7wLpXzGax7L6q8UL3SirfIugHAnGA55nmjmM+LQ/3sl2aswNNAJyCL75JNhTi3xb3Ujfad/F/qfFuCsnITdIGcCrwDnOju2wGCrw2DasXFXZbHMxkYAxwI3v8A+NLd98fYd0FcwfqvgvplFW9L4HPgUYt0+z1sZjWpoOfX3bcC9wAfA9uJnK8VVNzzm6+0zufJwXLR8jANI/JXPoeJK1b5oX72S4WZnQ9sdfdVRVZV6HOrZPOdWH2V5XZfuJklAc8Av3f33YeqGqPMD1FeqsysP/CZu68oQUyHWldW5z+RSLfEA+5+KrCXSDdPccr7/NYFLiDShdMYqAmcd4h9l/f5PZwjja9M4zazccB+YE5+0RHGFWq8ZlYDGAfcHGv1EcZUpudWyeY7W4j0g+ZrAmwrj0DMrCqRRDPH3ecHxZ+aWaNgfSPgs6C8uLjL6nh+DJxvZlnAk0S60iYDJ5hZ/rP3ovddEFewvg7wRRnGuwXY4u7vBO+fJpJ8Kur5/Smwyd0/d/dcYD5wJhX3/OYrrfO5JVguWl7qgoHz/sDlHvQrHUW8Oyj+e1MafkjkD49Vwe9cE+A/ZnbSUcRaZucW0JhNVH9lIpGBsxZ8N+CXUg5xGPA4MLlI+d0UHnCdGCynU3hQcGlQXo/I2ETd4LUJqBdy7Gl8d4PAPAoPkl4TLP+GwgPYfwuWUyg8EPsh4d0g8AbQJlgeH5zbCnl+gW7AWqBGEMMs4NqKdn45eMym1M4nsCyomz+I3S+EeM8F1gENitSLed44xOdFcd+b0oq1yLosvhuzqRDnttjjCKvheHwRuZvjfSJ3mYwrpxh6ELmUXQ1kBq9+RPqCXwM2Bl/zf1gMuC+IeQ3QNaqtYcB/g9fQMog9je+STUsid7r8N/jlqxaUHx+8/2+wvmXU9uOC49hAmHfFQCqwPDjHzwW/gBX2/AK3Au8B7wKzgw++CnN+gblExpNyify1PLw0zyfQNTj2D4DpFLm5o5Ti/S+RcY3837kZhztvFPN5Udz3prRiLbI+i++STbmf20O99LgaEREJncZsREQkdEo2IiISOiUbEREJnZKNiIiETslGRERCl3j4KiJSGswsj8gtqfkudPescgpHpEzp1meRMmJm2e6eVIb7S/TvntElUq7UjSZSQZhZIzP7l5llBnPXnBWUn2tm/zGzVWb2WlBWz8yeC+Yt+beZdQzKx5vZTDN7FXjcIvMM3W1my4K6V5fjIcr3mLrRRMpOdTPLDJY3ufuAIut/SeRx9H8yswSghpk1AB4Cerr7JjOrF9S9FVjp7hea2TlEHnGUGqzrAvRw9xwzuwr4yt1PM7NqwBIze9XdN4V5oCJFKdmIlJ0cd089xPplwF+CB7E+5+6ZZpYG/Cs/Obj7F0HdHsBFQdnrZvYDM6sTrHve3XOC5T5ARzO7OHhfB2hN5PlYImVGyUakgnD3f5lZTyIPVJxtZncDXxL7se+Hejz83iL1rnX3haUarMgR0piNSAVhZs2IzA30EPAIkakP3gbONrMWQZ38brR/AZcHZWnADo8979FC4NfB1RJm9qNgsjiRMqUrG5GKIw24wcxygWxgsLt/Hoy7zDezKkTmhelNZGqER81sNfA1cEUxbT5M5BH1/zEzIzJL6YVhHoRILLr1WUREQqduNBERCZ2SjYiIhE7JRkREQqdkIyIioVOyERGR0CnZiIhI6JRsREQkdP8Pl2dyhutcQBYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb.plot_importance(xg_clf)\n",
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, predictors, target, useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain[target],eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % accuracy_score(dtrain[target].values, dtrain_predictions))\n",
    "    print(\"AUC Score (Train): %f\" % roc_auc_score(dtrain[target], dtrain_predprob))\n",
    "\n",
    "    return alg\n",
    "#     feat_imp = pd.Series(alg.get_booster().get_fscore())\n",
    "#     feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "#     plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train  = pd.concat([X_train, y_train], axis=1)\n",
    "target = 'Survived'\n",
    "IDcol = 'PassengerId'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>youngin</th>\n",
       "      <th>male</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34.3750</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>876</td>\n",
       "      <td>3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>641</td>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>885</td>\n",
       "      <td>3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass   Age  SibSp  Parch     Fare  youngin  male  Q  S  \\\n",
       "PassengerId                                                             \n",
       "740               3  24.0      0      0   7.8958        0     1  0  1   \n",
       "148               3   9.0      2      2  34.3750        1     0  0  1   \n",
       "876               3  15.0      0      0   7.2250        0     0  0  0   \n",
       "641               3  20.0      0      0   7.8542        0     1  0  1   \n",
       "885               3  25.0      0      0   7.0500        0     1  0  1   \n",
       "\n",
       "             Survived  \n",
       "PassengerId            \n",
       "740                 0  \n",
       "148                 0  \n",
       "876                 1  \n",
       "641                 0  \n",
       "885                 0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.8919\n",
      "AUC Score (Train): 0.939281\n"
     ]
    }
   ],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = [x for x in train.columns if x not in [target, IDcol]]\n",
    "xgb1 = xgb.XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=3,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.6,\n",
    " colsample_bytree=0.3,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "\n",
    "alg = modelfit(xgb1, train, predictors, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.802691\n",
      "F1: 0.702703\n"
     ]
    }
   ],
   "source": [
    "preds = alg.predict(X_test)\n",
    "\n",
    "\n",
    "test_f1 = f1_score(y_test, preds)\n",
    "test_acc = accuracy_score(y_test, preds)\n",
    "\n",
    "print(\"Accuracy: %f\" % (test_acc))\n",
    "print(\"F1: %f\" % (test_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining XGBoost with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf_xgb = xgb.XGBClassifier(objective = 'binary:logistic')\n",
    "param_dist = {'n_estimators': [400,500, 600],\n",
    "              'learning_rate': [0.07,0.08,0.06],\n",
    "              'max_depth': [6],\n",
    "              'colsample_bytree': [0.7, 0.5, .6],\n",
    "              'min_child_weight': [3,4]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate the Gridsearch model\n",
    "gsearch1 = GridSearchCV(\n",
    "    estimator = clf_xgb,\n",
    "    param_grid = param_dist, \n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    iid=False, \n",
    "    cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   26.3s\n",
      "[Parallel(n_jobs=-1)]: Done 270 out of 270 | elapsed:   37.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1, gamma=0,\n",
       "                                     learning_rate=0.1, max_delta_step=0,\n",
       "                                     max_depth=3, min_child_weight=1,\n",
       "                                     missing=None, n_estimators=100, n_jobs=1,\n",
       "                                     nthread=None, objective='binary:logistic',\n",
       "                                     random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                                     scale_pos_weight=1, seed=None, silent=None,\n",
       "                                     subsample=1, verbosity=1),\n",
       "             iid=False, n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.7, 0.5, 0.6],\n",
       "                         'learning_rate': [0.07, 0.08, 0.06], 'max_depth': [6],\n",
       "                         'min_child_weight': [3, 4],\n",
       "                         'n_estimators': [400, 500, 600]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.fit(train[predictors],train[target])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.39890676, 0.49567013, 0.58200941, 0.38491592, 0.46693926,\n",
       "        0.61550851, 0.44830995, 0.49457784, 0.57547073, 0.38610625,\n",
       "        0.48566141, 0.56885672, 0.39699497, 0.49910884, 0.60582037,\n",
       "        0.40779161, 0.48690658, 0.60301261, 0.34565821, 0.42823739,\n",
       "        0.50081291, 0.33789129, 0.41812272, 0.50117621, 0.34657521,\n",
       "        0.43591914, 0.51473932, 0.34349618, 0.42272439, 0.5050776 ,\n",
       "        0.35369802, 0.43773012, 0.53812132, 0.35662842, 0.44203892,\n",
       "        0.52362723, 0.41278534, 0.49573588, 0.86889977, 0.56236157,\n",
       "        0.63504233, 0.82905741, 0.56397877, 0.54417925, 0.59943943,\n",
       "        0.39346256, 0.49513459, 0.58812599, 0.41532583, 0.50567141,\n",
       "        0.68248205, 0.45519128, 0.54162207, 0.54998255]),\n",
       " 'std_fit_time': array([0.02143461, 0.01879118, 0.01238017, 0.01271754, 0.00476522,\n",
       "        0.06813931, 0.05219304, 0.01703768, 0.01584777, 0.01795433,\n",
       "        0.01091627, 0.00759323, 0.00504815, 0.00628034, 0.01894408,\n",
       "        0.01666339, 0.00564194, 0.00525579, 0.00402184, 0.00646561,\n",
       "        0.00702456, 0.00390356, 0.00822833, 0.01037826, 0.0038737 ,\n",
       "        0.0042405 , 0.01387976, 0.00390759, 0.01014936, 0.00474057,\n",
       "        0.00888036, 0.00380595, 0.00621277, 0.00721754, 0.00425376,\n",
       "        0.0151396 , 0.01418822, 0.00459863, 0.08543225, 0.07049466,\n",
       "        0.10118641, 0.04923935, 0.01670388, 0.03309875, 0.02470407,\n",
       "        0.0019916 , 0.0061878 , 0.00365169, 0.0056224 , 0.00229047,\n",
       "        0.07391231, 0.05715698, 0.01385974, 0.06641791]),\n",
       " 'mean_score_time': array([0.0080812 , 0.00817232, 0.00967202, 0.00736566, 0.00749931,\n",
       "        0.01195364, 0.00809379, 0.00835252, 0.0088438 , 0.00710239,\n",
       "        0.00736842, 0.00817432, 0.00696344, 0.00869246, 0.00882921,\n",
       "        0.00716457, 0.00865202, 0.00807948, 0.00785565, 0.00822234,\n",
       "        0.0092783 , 0.00738587, 0.00785394, 0.00893846, 0.00768948,\n",
       "        0.00804739, 0.01015372, 0.00752563, 0.008883  , 0.00916114,\n",
       "        0.00822964, 0.00859599, 0.01129203, 0.00749378, 0.00889606,\n",
       "        0.00875864, 0.00742331, 0.00908937, 0.02551346, 0.00891757,\n",
       "        0.00916061, 0.01160378, 0.00821552, 0.00905743, 0.0110796 ,\n",
       "        0.00943861, 0.0089653 , 0.00934505, 0.00769801, 0.00872722,\n",
       "        0.01068363, 0.00788651, 0.01020942, 0.00783353]),\n",
       " 'std_score_time': array([0.0011579 , 0.00029769, 0.00163284, 0.00084668, 0.00040305,\n",
       "        0.00366477, 0.00171945, 0.00096881, 0.00053996, 0.00132243,\n",
       "        0.0001985 , 0.00034248, 0.00027153, 0.00067748, 0.0006964 ,\n",
       "        0.00106648, 0.00128779, 0.00018297, 0.00146203, 0.00062448,\n",
       "        0.00073555, 0.00126496, 0.00080548, 0.0010288 , 0.00169975,\n",
       "        0.0002823 , 0.00103826, 0.00120956, 0.00147868, 0.00096565,\n",
       "        0.00180473, 0.00071795, 0.00227525, 0.00046883, 0.00162426,\n",
       "        0.00022523, 0.00038916, 0.00112083, 0.01370178, 0.00248806,\n",
       "        0.00154699, 0.00244479, 0.00093283, 0.0006661 , 0.00124626,\n",
       "        0.00251804, 0.00137818, 0.00039199, 0.00017996, 0.00024858,\n",
       "        0.00082875, 0.00086121, 0.0041185 , 0.00163752]),\n",
       " 'param_colsample_bytree': masked_array(data=[0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6,\n",
       "                    0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate': masked_array(data=[0.07, 0.07, 0.07, 0.07, 0.07, 0.07, 0.08, 0.08, 0.08,\n",
       "                    0.08, 0.08, 0.08, 0.06, 0.06, 0.06, 0.06, 0.06, 0.06,\n",
       "                    0.07, 0.07, 0.07, 0.07, 0.07, 0.07, 0.08, 0.08, 0.08,\n",
       "                    0.08, 0.08, 0.08, 0.06, 0.06, 0.06, 0.06, 0.06, 0.06,\n",
       "                    0.07, 0.07, 0.07, 0.07, 0.07, 0.07, 0.08, 0.08, 0.08,\n",
       "                    0.08, 0.08, 0.08, 0.06, 0.06, 0.06, 0.06, 0.06, 0.06],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_child_weight': masked_array(data=[3, 3, 3, 4, 4, 4, 3, 3, 3, 4, 4, 4, 3, 3, 3, 4, 4, 4,\n",
       "                    3, 3, 3, 4, 4, 4, 3, 3, 3, 4, 4, 4, 3, 3, 3, 4, 4, 4,\n",
       "                    3, 3, 3, 4, 4, 4, 3, 3, 3, 4, 4, 4, 3, 3, 3, 4, 4, 4],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[400, 500, 600, 400, 500, 600, 400, 500, 600, 400, 500,\n",
       "                    600, 400, 500, 600, 400, 500, 600, 400, 500, 600, 400,\n",
       "                    500, 600, 400, 500, 600, 400, 500, 600, 400, 500, 600,\n",
       "                    400, 500, 600, 400, 500, 600, 400, 500, 600, 400, 500,\n",
       "                    600, 400, 500, 600, 400, 500, 600, 400, 500, 600],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 600},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 400},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 600},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.08,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.08,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.08,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 600},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.08,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 400},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.08,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.08,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 600},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.06,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.06,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.06,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 600},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.06,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 400},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.06,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'learning_rate': 0.06,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 600},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 600},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 400},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 600},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.08,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.08,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.08,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 600},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.08,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 400},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.08,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.08,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 600},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.06,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.06,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.06,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 600},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.06,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 400},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.06,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.5,\n",
       "   'learning_rate': 0.06,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 600},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 600},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 400},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.07,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 600},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.08,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.08,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.08,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 600},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.08,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 400},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.08,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.08,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 600},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.06,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 400},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.06,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.06,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 3,\n",
       "   'n_estimators': 600},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.06,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 400},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.06,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'learning_rate': 0.06,\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 4,\n",
       "   'n_estimators': 600}],\n",
       " 'split0_test_score': array([0.84313725, 0.85148515, 0.84313725, 0.85436893, 0.84615385,\n",
       "        0.84615385, 0.85148515, 0.85148515, 0.82692308, 0.84313725,\n",
       "        0.84313725, 0.83495146, 0.84313725, 0.85148515, 0.85148515,\n",
       "        0.8627451 , 0.8627451 , 0.8627451 , 0.85148515, 0.84313725,\n",
       "        0.83495146, 0.84313725, 0.84313725, 0.85436893, 0.84313725,\n",
       "        0.83495146, 0.82692308, 0.85148515, 0.8627451 , 0.85436893,\n",
       "        0.85436893, 0.85148515, 0.83495146, 0.86538462, 0.85436893,\n",
       "        0.85436893, 0.84313725, 0.85148515, 0.85148515, 0.8627451 ,\n",
       "        0.85436893, 0.85436893, 0.84313725, 0.83495146, 0.83809524,\n",
       "        0.84313725, 0.84313725, 0.84615385, 0.85148515, 0.84313725,\n",
       "        0.85148515, 0.8627451 , 0.8627451 , 0.87378641]),\n",
       " 'split1_test_score': array([0.75510204, 0.78431373, 0.77227723, 0.74226804, 0.75510204,\n",
       "        0.76      , 0.79207921, 0.7961165 , 0.76190476, 0.78      ,\n",
       "        0.7755102 , 0.78      , 0.75510204, 0.75510204, 0.77227723,\n",
       "        0.72916667, 0.74226804, 0.75510204, 0.74      , 0.76470588,\n",
       "        0.76470588, 0.7628866 , 0.75      , 0.74      , 0.78      ,\n",
       "        0.78431373, 0.78846154, 0.7628866 , 0.74747475, 0.74      ,\n",
       "        0.72727273, 0.72727273, 0.76      , 0.75510204, 0.75510204,\n",
       "        0.74      , 0.73469388, 0.77227723, 0.76      , 0.73469388,\n",
       "        0.75510204, 0.76767677, 0.78      , 0.77227723, 0.75728155,\n",
       "        0.75510204, 0.74747475, 0.74747475, 0.73267327, 0.75728155,\n",
       "        0.76470588, 0.7628866 , 0.75510204, 0.76      ]),\n",
       " 'split2_test_score': array([0.72727273, 0.73873874, 0.73873874, 0.72222222, 0.72897196,\n",
       "        0.72897196, 0.72222222, 0.73394495, 0.73394495, 0.72222222,\n",
       "        0.72222222, 0.72222222, 0.74545455, 0.73394495, 0.73394495,\n",
       "        0.73394495, 0.73394495, 0.72222222, 0.75471698, 0.75471698,\n",
       "        0.73394495, 0.75229358, 0.72897196, 0.74074074, 0.75471698,\n",
       "        0.73394495, 0.73394495, 0.72897196, 0.72897196, 0.72897196,\n",
       "        0.74285714, 0.75471698, 0.75471698, 0.72897196, 0.74074074,\n",
       "        0.72897196, 0.74074074, 0.73394495, 0.73394495, 0.75229358,\n",
       "        0.74074074, 0.74074074, 0.73394495, 0.73394495, 0.73394495,\n",
       "        0.75229358, 0.72897196, 0.72897196, 0.77358491, 0.73394495,\n",
       "        0.73394495, 0.72897196, 0.72897196, 0.74074074]),\n",
       " 'split3_test_score': array([0.81553398, 0.8       , 0.78095238, 0.80392157, 0.80769231,\n",
       "        0.7961165 , 0.80769231, 0.78846154, 0.7961165 , 0.7961165 ,\n",
       "        0.7961165 , 0.78846154, 0.81553398, 0.81553398, 0.78846154,\n",
       "        0.7961165 , 0.81188119, 0.81553398, 0.81553398, 0.81553398,\n",
       "        0.8       , 0.82352941, 0.81188119, 0.82352941, 0.80392157,\n",
       "        0.80769231, 0.78504673, 0.81188119, 0.80392157, 0.81553398,\n",
       "        0.7961165 , 0.80392157, 0.7961165 , 0.81553398, 0.81553398,\n",
       "        0.80392157, 0.80392157, 0.80392157, 0.78095238, 0.80392157,\n",
       "        0.80392157, 0.81553398, 0.80392157, 0.78846154, 0.78846154,\n",
       "        0.80392157, 0.80392157, 0.78846154, 0.80392157, 0.7961165 ,\n",
       "        0.7961165 , 0.81553398, 0.82692308, 0.82692308]),\n",
       " 'split4_test_score': array([0.7755102 , 0.78787879, 0.8       , 0.79591837, 0.80808081,\n",
       "        0.80808081, 0.8       , 0.8       , 0.8       , 0.80808081,\n",
       "        0.8       , 0.80808081, 0.77083333, 0.7628866 , 0.7755102 ,\n",
       "        0.78350515, 0.78350515, 0.79591837, 0.75789474, 0.7755102 ,\n",
       "        0.78      , 0.77083333, 0.77083333, 0.77083333, 0.7628866 ,\n",
       "        0.7628866 , 0.7755102 , 0.77083333, 0.77083333, 0.7755102 ,\n",
       "        0.75789474, 0.7755102 , 0.7755102 , 0.78350515, 0.78350515,\n",
       "        0.77083333, 0.7628866 , 0.78787879, 0.7755102 , 0.78350515,\n",
       "        0.78350515, 0.79591837, 0.78787879, 0.78787879, 0.8       ,\n",
       "        0.78350515, 0.8       , 0.81188119, 0.7628866 , 0.7628866 ,\n",
       "        0.7628866 , 0.78350515, 0.78350515, 0.79591837]),\n",
       " 'mean_test_score': array([0.78331124, 0.79248328, 0.78702112, 0.78373983, 0.78920019,\n",
       "        0.78786462, 0.79469578, 0.79400163, 0.78377786, 0.78991136,\n",
       "        0.78739724, 0.78674321, 0.78601223, 0.78379054, 0.78433581,\n",
       "        0.78109568, 0.78686889, 0.79030434, 0.78392617, 0.79072086,\n",
       "        0.78272046, 0.79053604, 0.78096475, 0.78589448, 0.78893248,\n",
       "        0.78475781, 0.7819773 , 0.78521165, 0.78278934, 0.78287702,\n",
       "        0.77570201, 0.78258133, 0.78425903, 0.78969955, 0.78985017,\n",
       "        0.77961916, 0.77707601, 0.78990154, 0.78037854, 0.78743186,\n",
       "        0.78752769, 0.79484776, 0.78977651, 0.78350279, 0.78355666,\n",
       "        0.78759192, 0.78470111, 0.78458866, 0.7849103 , 0.77867337,\n",
       "        0.78182782, 0.79072856, 0.79144947, 0.79947372]),\n",
       " 'std_test_score': array([0.04150756, 0.03609471, 0.03435949, 0.04700726, 0.04179062,\n",
       "        0.04029691, 0.04166855, 0.03736925, 0.03236869, 0.03970311,\n",
       "        0.03932147, 0.03739174, 0.03732443, 0.04320832, 0.03818008,\n",
       "        0.04861661, 0.04729547, 0.04855943, 0.04248197, 0.03336942,\n",
       "        0.03387517, 0.03597395, 0.04143901, 0.04577585, 0.03191146,\n",
       "        0.03494535, 0.02973388, 0.04235915, 0.04717175, 0.04685304,\n",
       "        0.04548959, 0.04263474, 0.02914823, 0.04757908, 0.04118679,\n",
       "        0.0455854 , 0.04099417, 0.03856151, 0.03911916, 0.04466633,\n",
       "        0.03998283, 0.03908367, 0.03539434, 0.03247367, 0.03583462,\n",
       "        0.03367554, 0.04125483, 0.04247544, 0.04033771, 0.03786111,\n",
       "        0.04000252, 0.04570103, 0.04822682, 0.04753151]),\n",
       " 'rank_test_score': array([41,  5, 23, 38, 16, 18,  3,  4, 37, 11, 22, 25, 26, 36, 33, 48, 24,\n",
       "        10, 35,  8, 44,  9, 49, 27, 17, 30, 46, 28, 43, 42, 54, 45, 34, 15,\n",
       "        13, 51, 53, 12, 50, 21, 20,  2, 14, 40, 39, 19, 31, 32, 29, 52, 47,\n",
       "         7,  6,  1], dtype=int32)}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.6,\n",
       " 'learning_rate': 0.06,\n",
       " 'max_depth': 6,\n",
       " 'min_child_weight': 4,\n",
       " 'n_estimators': 600}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7994737185555494"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.780269\n",
      "F1: 0.662069\n"
     ]
    }
   ],
   "source": [
    "preds = gsearch1.best_estimator_.predict(X_test)\n",
    "\n",
    "\n",
    "test_f1 = f1_score(y_test, preds)\n",
    "\n",
    "test_acc = accuracy_score(y_test, preds)\n",
    "\n",
    "print(\"Accuracy: %f\" % (test_acc))\n",
    "print(\"F1: %f\" % (test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1f3eb950>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# plot feature importance\n",
    "plot_importance(alg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fare': 231,\n",
       " 'Parch': 91,\n",
       " 'male': 42,\n",
       " 'Pclass': 81,\n",
       " 'SibSp': 86,\n",
       " 'S': 43,\n",
       " 'Q': 37,\n",
       " 'youngin': 27,\n",
       " 'Age': 150}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg.get_booster().get_fscore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_clf = xgb.train(params=params, dtrain=data_dmatrix, num_boost_round=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle list object\n",
    " \n",
    "model_pickle_path = 'xg_boost_model.pkl'\n",
    "\n",
    "# Create an variable to pickle and open it in write mode\n",
    "model_pickle = open(model_pickle_path, 'wb')\n",
    "pickle.dump(gsearch1.best_estimator_, model_pickle)\n",
    "model_pickle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded XGboost model ::  XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.6, gamma=0,\n",
      "              learning_rate=0.06, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=4, missing=nan, n_estimators=600, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n"
     ]
    }
   ],
   "source": [
    "# Loading the saved XGboost model pickle\n",
    "xgboost_model_pkl = open(model_pickle_path, 'rb')\n",
    "xgboost_model = pickle.load(xgboost_model_pkl)\n",
    "print(\"Loaded XGboost model :: \", xgboost_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(9,12)\n",
    "    for min_child_weight in range(5,8)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9, 5), (9, 6), (9, 7), (10, 5), (10, 6), (10, 7), (11, 5), (11, 6), (11, 7)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
